import os
import pyaudio
import boto3
import json
import asyncio
from dotenv import load_dotenv
import time
import threading
import queue
from collections import deque
import openai
from amazon_transcribe.client import TranscribeStreamingClient
from amazon_transcribe.handlers import TranscriptResultStreamHandler
from amazon_transcribe.model import TranscriptEvent
from websocket import WebSocketApp
import re

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API ì„¤ì •
openai.api_key = os.getenv('OPENAI_API_KEY')

class Config:
    def __init__(self):
        self.CONTEXT_SIZE = 10
        self.CHUNK = 1024
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        self.SILENCE_THRESHOLD = 0.05
        self.SILENCE_DURATION = 0.5

class SentenceManager:
    def __init__(self, config):
        self.context = deque(maxlen=config.CONTEXT_SIZE)
        self.correction_queue = queue.Queue(maxsize=100)
        self.translation_queue = queue.Queue(maxsize=100)
        self.last_sentence_time = time.time()
        self.min_sentence_interval = 0.1
        self.accumulated_text = ""  # ëˆ„ì ëœ í…ìŠ¤íŠ¸ ì €ì¥
        self.last_text_time = time.time()  # ë§ˆì§€ë§‰ í…ìŠ¤íŠ¸ ìˆ˜ì‹  ì‹œê°„
        self.max_wait_time = 4.0  # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        self.completed_sentences = deque(maxlen=5)  # ì™„ì„±ëœ ë¬¸ì¥ íˆìŠ¤í† ë¦¬
        
    def add_text(self, text):
        """ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ê³  ë¬¸ì¥ ì™„ì„±ë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
        self.context.append(text)
        self.accumulated_text += " " + text if self.accumulated_text else text
        self.last_text_time = time.time()
        
        # OpenAI APIë¥¼ ì‚¬ìš©í•œ ë¬¸ì¥ ì™„ì„± í™•ì¸ (íƒ€ì„ì•„ì›ƒ í¬í•¨)
        return self.check_sentence_completion()
        
    def check_sentence_completion_simple(self):
        """ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì¥ ì™„ì„±ë„ë¥¼ ë” ì •êµí•˜ê²Œ í™•ì¸í•©ë‹ˆë‹¤."""
        if not self.accumulated_text:
            return False, ""

        text = self.accumulated_text.strip()
        
        # ë¬¼ìŒí‘œë¡œ ëë‚˜ëŠ” ê²½ìš° ì¦‰ì‹œ ì™„ì„±ëœ ë¬¸ì¥ìœ¼ë¡œ ì²˜ë¦¬
        if text.endswith("?"):
            complete_sentence = text
            self.completed_sentences.append(complete_sentence)
            self.accumulated_text = ""
            self.context.clear()
            return True, complete_sentence

        # ë‹¤ì–‘í•œ ì¢…ê²° ì–´ë¯¸ ë° íŠ¹ìˆ˜ë¬¸ì íŒ¨í„´ (ì˜ë¬¸í˜• ì–´ë¯¸ ì¶”ê°€)
        sentence_ending_pattern = re.compile(
            r"(ë‹¤|ìš”|ê¹Œ|ì£ |ë„¤|ìŠµë‹ˆë‹¤|í•©ë‹ˆë‹¤|ë©ë‹ˆë‹¤|ì…ë‹ˆë‹¤|êµ°ìš”|ë„¤ìš”|ëë‹ˆë‹¤|ë¼ìš”|êµ¬ë‚˜|êµ¬ìš”|"
            r"ê² ë„¤|ê² êµ°ìš”|ê² ì–´ìš”|ê² ìŠµë‹ˆê¹Œ|ì‹­ì‹œì˜¤|ì„¸ìš”|ì|ì£ |ë¼|ë ´|êµ¬ë ¤|êµ¬ìš”|ì§€ìš”|"
            r"ã„¹ê¹Œ|ì„ê¹Œ|ë‚˜ìš”|ã„´ê°€ìš”|ã„´ê°€|ëŠ”ê°€|ë˜ê°€)"  # ì˜ë¬¸í˜• ì–´ë¯¸ ì¶”ê°€
            r"[\s\.!?\)\]\}\"\u2018\u2019\u201c\u201d]*$"  # ìœ ë‹ˆì½”ë“œë¡œ ë”°ì˜´í‘œ í‘œí˜„
        )

        if sentence_ending_pattern.search(text):
            complete_sentence = text
            self.completed_sentences.append(complete_sentence)
            self.accumulated_text = ""
            self.context.clear()
            return True, complete_sentence

        # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ ì‹œ ê°•ì œë¡œ ë¬¸ì¥ ì™„ì„± ì²˜ë¦¬ (ê¸€ì ìˆ˜ ì œí•œ ì™„í™”)
        if time.time() - self.last_text_time > self.max_wait_time and len(text) > 2:  # 10 -> 2ë¡œ ì™„í™”
            complete_sentence = text
            self.completed_sentences.append(complete_sentence)
            self.accumulated_text = ""
            self.context.clear()
            return True, complete_sentence

        return False, ""
        
    def check_sentence_completion(self):
        """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ê°€ ì™„ì „í•œ ë¬¸ì¥ì¸ì§€ í™•ì¸í•˜ê³  ì •ì œí•©ë‹ˆë‹¤."""
        if not self.accumulated_text:
            return False, ""
            
        # ëˆ„ì ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
        combined_text = self.accumulated_text.strip()
        
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
        if len(combined_text) < 5:
            return False, ""
        
        # ì´ì „ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ (ìµœê·¼ 5ê°œê¹Œì§€ë§Œ ì‚¬ìš©)
        recent_context = list(self.context)[-5:] if len(self.context) > 5 else list(self.context)
        context_text = " ".join(recent_context) if recent_context else ""
        
        # ì´ì „ ì™„ì„±ëœ ë¬¸ì¥ë“¤ë„ ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨
        previous_sentences = " ".join(list(self.completed_sentences)[-3:]) if self.completed_sentences else ""
        
        try:
            # OpenAI API í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
            response = openai.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì™„ì „í•œ ë¬¸ì¥ì¸ì§€ í™•ì¸í•˜ê³ , 
                        ì™„ì „í•œ ë¬¸ì¥ì´ë©´ ë¬¸ì¥ì„ ì •ì œí•˜ì—¬ ë°˜í™˜í•´ì£¼ì„¸ìš”.
                        ì´ì „ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  íŒë‹¨í•´ì£¼ì„¸ìš”.
                        ê°€ëŠ¥í•œ ë²ˆì—­ì´ ì˜ë  ë¬¸ì¥ í˜•íƒœë¡œ ë§Œë“¤ì–´ì£¼ì–´ì•¼ í•´ìš”.
                        ì‘ë‹µì€ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ í•´ì£¼ì„¸ìš”:
                        {
                            "is_complete": true/false,
                            "sentence": "ì™„ì „í•œ ë¬¸ì¥ì´ë©´ ì •ì œëœ ë¬¸ì¥, ì•„ë‹ˆë©´ ë¹ˆ ë¬¸ìì—´"
                        }"""
                    },
                    {
                        "role": "user",
                        "content": f"ì´ì „ ì™„ì„±ëœ ë¬¸ì¥ë“¤: {previous_sentences}\n\nìµœê·¼ ì»¨í…ìŠ¤íŠ¸: {context_text}\n\ní˜„ì¬ í…ìŠ¤íŠ¸: {combined_text}"
                    }
                ],
                temperature=0.1,
                timeout=2  # 2ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •
            )
            
            # ì‘ë‹µ íŒŒì‹±
            result = json.loads(response.choices[0].message.content)
            
            if result.get('is_complete', False):
                sentence = result.get('sentence', combined_text)
                # ì™„ì„±ëœ ë¬¸ì¥ì„ íˆìŠ¤í† ë¦¬ì— ì €ì¥
                self.completed_sentences.append(sentence)
                # ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
                self.context.clear()
                self.accumulated_text = ""  # ëˆ„ì  í…ìŠ¤íŠ¸ë„ ì´ˆê¸°í™”
                return True, sentence
            
            return False, ""
            
        except Exception as e:
            print(f"OpenAI API ì˜¤ë¥˜ ë˜ëŠ” íƒ€ì„ì•„ì›ƒ: {str(e)}")
            # API ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´
            return self.check_sentence_completion_simple()

class TranscriptHandler(TranscriptResultStreamHandler):
    def __init__(self, translator, transcript_result_stream, config):
        super().__init__(transcript_result_stream)
        self.translator = translator
        self.config = config
        self.sentence_manager = SentenceManager(config)
        self.partial_results = []  # ë¶€ë¶„ ê²°ê³¼ ì €ì¥
        
    async def handle_transcript_event(self, transcript_event: TranscriptEvent):
        results = transcript_event.transcript.results
        if len(results) > 0:
            transcript = results[0]
            if transcript.is_partial:
                # ë¶€ë¶„ ê²°ê³¼ ì²˜ë¦¬
                self.partial_results.append(transcript.alternatives[0].transcript)
            else:
                # ìµœì¢… ê²°ê³¼ ì²˜ë¦¬
                text = transcript.alternatives[0].transcript
                if text and self._is_valid_sentence(text):
                    print(f"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text}")
                    self.sentence_manager.correction_queue.put(text)
                self.partial_results = []  # ë¶€ë¶„ ê²°ê³¼ ì´ˆê¸°í™”
                
    def _is_valid_sentence(self, text):
        # ë¬¸ì¥ ìœ íš¨ì„± ê²€ì‚¬
        current_time = time.time()
        if current_time - self.sentence_manager.last_sentence_time < self.sentence_manager.min_sentence_interval:
            return False
        self.sentence_manager.last_sentence_time = current_time
        return True

class WebSocketClient:
    def __init__(self, websocket_url):
        self.websocket_url = websocket_url
        self.ws = None
        self.connected = False
        self.ws_thread = None
        self.message_queue = queue.Queue()

    def connect(self):
        def on_message(ws, message):
            print(f"ì„œë²„ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ : {message}")

        def on_error(ws, error):
            print(f"WebSocket ì—ëŸ¬: {error}")

        def on_close(ws, close_status_code, close_msg):
            print(f"WebSocket ì—°ê²° ì¢…ë£Œ: {close_status_code} - {close_msg}")
            self.connected = False

        def on_open(ws):
            print("WebSocket ì—°ê²° ì„±ê³µ!")
            self.connected = True

        self.ws = WebSocketApp(
            self.websocket_url,
            on_open=on_open,
            on_message=on_message,
            on_error=on_error,
            on_close=on_close
        )

        self.ws_thread = threading.Thread(target=self.ws.run_forever)
        self.ws_thread.daemon = True
        self.ws_thread.start()

        # ì—°ê²° ëŒ€ê¸°
        timeout = 5
        start_time = time.time()
        while not self.connected and time.time() - start_time < timeout:
            time.sleep(0.1)

        if not self.connected:
            raise Exception("WebSocket ì—°ê²° ì‹¤íŒ¨")

    def send_message(self, sender, message, translation):
        if not self.connected:
            raise Exception("WebSocketì´ ì—°ê²°ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

        message_data = {
            "action": "sendMessage",
            "sender": sender,
            "message": {
                "original": message,
                "translation": translation
            }
        }
        self.ws.send(json.dumps(message_data))

    def close(self):
        if self.ws:
            self.ws.close()
        if self.ws_thread:
            self.ws_thread.join(timeout=1)

class VoiceTranslator:
    def __init__(self):
        start_time = time.time()
        print(f"ì´ˆê¸°í™” ì‹œì‘ ì‹œê°„: {time.strftime('%H:%M:%S')}")
        
        # ì„¤ì • ë¡œë“œ
        self.config = Config()
        print(f"ì„¤ì • ë¡œë“œ ì™„ë£Œ: {time.time() - start_time:.2f}ì´ˆ")
        
        # ë§ˆì´í¬ ì„ íƒ
        self.selected_mic_index = self.select_microphone()
        print(f"ë§ˆì´í¬ ì„ íƒ ì™„ë£Œ: {time.time() - start_time:.2f}ì´ˆ")
        
        # AWS ìê²© ì¦ëª… ì„¤ì •
        self.region = os.getenv('AWS_REGION', 'ap-northeast-2')
        self.translate_client = boto3.client('translate',
            aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),
            aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),
            region_name=self.region
        )
        print(f"AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {time.time() - start_time:.2f}ì´ˆ")
        
        # Transcribe ìŠ¤íŠ¸ë¦¬ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        self.client = TranscribeStreamingClient(region=self.region)
        print(f"Transcribe í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {time.time() - start_time:.2f}ì´ˆ")
        
        # WebSocket í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        websocket_url = os.getenv('WEBSOCKET_URL')
        if not websocket_url:
            raise ValueError("WEBSOCKET_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        self.ws_client = WebSocketClient(websocket_url)
        self.ws_client.connect()
        print(f"WebSocket ì—°ê²° ì™„ë£Œ: {time.time() - start_time:.2f}ì´ˆ")
        
        # ìŠ¤ë ˆë“œ ì œì–´
        self.running = True
        
        # ìŠ¤ë ˆë“œ ì´ˆê¸°í™”
        self.correction_thread = None
        self.translation_thread = None
        self.message_thread = None
        
        print(f"ì „ì²´ ì´ˆê¸°í™” ì™„ë£Œ: {time.time() - start_time:.2f}ì´ˆ")
        
    def select_microphone(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë§ˆì´í¬ë¥¼ ë‚˜ì—´í•˜ê³  ì‚¬ìš©ìê°€ ì„ íƒí•˜ë„ë¡ í•©ë‹ˆë‹¤."""
        p = pyaudio.PyAudio()
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë§ˆì´í¬ ì •ë³´ ìˆ˜ì§‘
        mic_info = []
        for i in range(p.get_device_count()):
            device_info = p.get_device_info_by_index(i)
            if device_info.get('maxInputChannels') > 0:  # ì…ë ¥ ì¥ì¹˜ë§Œ í‘œì‹œ
                mic_info.append({
                    'index': i,
                    'name': device_info.get('name', 'Unknown'),
                    'channels': device_info.get('maxInputChannels'),
                    'sample_rate': device_info.get('defaultSampleRate')
                })
        
        if not mic_info:
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ë§ˆì´í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            p.terminate()
            return None
            
        # ë§ˆì´í¬ ëª©ë¡ ì¶œë ¥
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ ë§ˆì´í¬ ëª©ë¡:")
        for i, mic in enumerate(mic_info):
            print(f"{i+1}. {mic['name']} (ì±„ë„: {mic['channels']}, ìƒ˜í”Œë ˆì´íŠ¸: {mic['sample_rate']}Hz)")
            
        # ì‚¬ìš©ì ì„ íƒ
        while True:
            try:
                choice = int(input("\nì‚¬ìš©í•  ë§ˆì´í¬ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-{}): ".format(len(mic_info))))
                if 1 <= choice <= len(mic_info):
                    selected_mic = mic_info[choice-1]
                    print(f"\nì„ íƒëœ ë§ˆì´í¬: {selected_mic['name']}")
                    p.terminate()
                    return selected_mic['index']
                else:
                    print("ìœ íš¨í•˜ì§€ ì•Šì€ ë²ˆí˜¸ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.")
            except ValueError:
                print("ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
    def translate_text(self, text):
        """AWS Translateë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì¼ë³¸ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤."""
        if not text:
            return ""
            
        try:
            response = self.translate_client.translate_text(
                Text=text,
                SourceLanguageCode='ko',
                TargetLanguageCode='ja'
            )
            return response['TranslatedText']
        except Exception as e:
            print(f"ë²ˆì—­ ì˜¤ë¥˜: {str(e)}")
            return ""
    
    def correction_worker(self, sentence_manager):
        """AI êµì • ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.running:
            try:
                # íì—ì„œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (0.5ì´ˆ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ë‹¨ì¶•)
                text = sentence_manager.correction_queue.get(timeout=0.5)
                # ë¬¸ì¥ ì™„ì„±ë„ í™•ì¸
                is_complete, complete_sentence = sentence_manager.add_text(text)
                if is_complete and complete_sentence:
                    print(f"ì™„ì„±ëœ ë¬¸ì¥: {complete_sentence}")
                    # ë²ˆì—­ì„ ìœ„í•œ í…ìŠ¤íŠ¸ë¥¼ íì— ì¶”ê°€
                    sentence_manager.translation_queue.put(complete_sentence)
                sentence_manager.correction_queue.task_done()
            except queue.Empty:
                # íê°€ ë¹„ì–´ìˆì„ ë•Œ ëŒ€ê¸° ì¤‘ì¸ í…ìŠ¤íŠ¸ í™•ì¸
                if sentence_manager.accumulated_text and \
                   time.time() - sentence_manager.last_text_time > sentence_manager.max_wait_time:
                    # ê°•ì œë¡œ ë¬¸ì¥ ì™„ì„± ì²˜ë¦¬
                    is_complete, complete_sentence = sentence_manager.check_sentence_completion_simple()
                    if is_complete and complete_sentence:
                        print(f"íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì™„ì„±ëœ ë¬¸ì¥: {complete_sentence}")
                        sentence_manager.translation_queue.put(complete_sentence)
                continue
            except Exception as e:
                print(f"êµì • ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {str(e)}")
                continue
    
    def translation_worker(self, sentence_manager):
        """ë²ˆì—­ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.running:
            try:
                # íì—ì„œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (1ì´ˆ íƒ€ì„ì•„ì›ƒ)
                text = sentence_manager.translation_queue.get(timeout=1)
                translated_text = self.translate_text(text)
                print(f"ë²ˆì—­ëœ í…ìŠ¤íŠ¸: {translated_text}")
                
                # WebSocketìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡
                self.ws_client.send_message("VoiceTranslator", text, translated_text)
                
                sentence_manager.translation_queue.task_done()
            except queue.Empty:
                continue
            except Exception as e:
                print(f"ë²ˆì—­ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {str(e)}")
                continue
    
    async def mic_stream(self):
        """ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤."""
        # ë§ˆì´í¬ ì´ˆê¸°í™”
        p = pyaudio.PyAudio()
        stream = p.open(
            format=self.config.FORMAT,
            channels=self.config.CHANNELS,
            rate=self.config.RATE,
            input=True,
            input_device_index=self.selected_mic_index,  # ì„ íƒëœ ë§ˆì´í¬ ì‚¬ìš©
            frames_per_buffer=self.config.CHUNK,
        )
        
        print("ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”)")
        
        try:
            while self.running:
                chunk = stream.read(self.config.CHUNK, exception_on_overflow=False)
                yield chunk
        except KeyboardInterrupt:
            print("\në…¹ìŒì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        finally:
            stream.stop_stream()
            stream.close()
            p.terminate()
            print("ë§ˆì´í¬ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    async def write_chunks(self, stream):
        """ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ìŠ¤íŠ¸ë¦¼ì— ì „ì†¡í•©ë‹ˆë‹¤."""
        async for chunk in self.mic_stream():
            await stream.input_stream.send_audio_event(audio_chunk=chunk)
        await stream.input_stream.end_stream()

    async def process_audio(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        try:
            print("\nğŸ¤ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("ì´ì œ ë§ì”€í•˜ì‹œë©´ ìë™ìœ¼ë¡œ ì¸ì‹ë˜ì–´ ë²ˆì—­ë©ë‹ˆë‹¤.")
            print("ì¢…ë£Œí•˜ì‹œë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n")
            
            # íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
            stream = await self.client.start_stream_transcription(
                language_code="ko-KR",
                media_sample_rate_hz=self.config.RATE,
                media_encoding="pcm",
                vocabulary_name="p2pVocabulary",  # ì‚¬ìš©ì ì •ì˜ ì‚¬ì „ ì¶”ê°€
                enable_partial_results_stabilization=True,  # ë¶€ë¶„ ê²°ê³¼ ì•ˆì •í™” í™œì„±í™”
                partial_results_stability="high",  # ë†’ì€ ì•ˆì •ì„± ì„¤ì •
            )
            
            # í•¸ë“¤ëŸ¬ ìƒì„± ë° ì—°ê²°
            handler = TranscriptHandler(self, stream.output_stream, self.config)
            
            # êµì • ìŠ¤ë ˆë“œ ì‹œì‘
            self.correction_thread = threading.Thread(
                target=self.correction_worker,
                args=(handler.sentence_manager,),
                daemon=True
            )
            self.correction_thread.start()
            
            # ë²ˆì—­ ìŠ¤ë ˆë“œ ì‹œì‘
            self.translation_thread = threading.Thread(
                target=self.translation_worker,
                args=(handler.sentence_manager,),
                daemon=True
            )
            self.translation_thread.start()
            
            # í•¸ë“¤ëŸ¬ ì—°ê²°
            await asyncio.gather(
                self.write_chunks(stream),
                handler.handle_events(),
            )
            
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            self.running = False
        finally:
            # í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ì •ë¦¬
            self.running = False
            if self.correction_thread and self.correction_thread.is_alive():
                self.correction_thread.join(timeout=1)
            if self.translation_thread and self.translation_thread.is_alive():
                self.translation_thread.join(timeout=1)
            self.ws_client.close()

async def main():
    translator = VoiceTranslator()
    await translator.process_audio()

if __name__ == "__main__":
    asyncio.run(main()) 
